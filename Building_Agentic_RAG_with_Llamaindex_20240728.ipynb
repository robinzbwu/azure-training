{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Agentic RAG with Multi-document + Tools Calling + ReAct"
      ],
      "metadata": {
        "id": "Fa-IcKgALU3d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparation Stage"
      ],
      "metadata": {
        "id": "l5We16Rr2PGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install \\\n",
        "\"python-dotenv==1.0.0\" \\\n",
        "\"openai==1.23.2\" \\\n",
        "\"llama-index==0.10.27\" \\\n",
        "\"llama-index-core==0.10.27\" \\\n",
        "\"llama-index-llms-openai==0.1.15\" \\\n",
        "\"llama-index-embeddings-openai==0.1.7\" \\\n",
        "\"llama-index-agent-openai==0.2.2\" \\\n",
        "\"nest-asyncio==1.6.0\""
      ],
      "metadata": {
        "id": "X-4np8FN5fFg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7b56d3e-1c94-4453-ac17-540e7455dda8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv==1.0.0\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting openai==1.23.2\n",
            "  Downloading openai-1.23.2-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting llama-index==0.10.27\n",
            "  Downloading llama_index-0.10.27-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting llama-index-core==0.10.27\n",
            "  Downloading llama_index_core-0.10.27-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting llama-index-llms-openai==0.1.15\n",
            "  Downloading llama_index_llms_openai-0.1.15-py3-none-any.whl.metadata (559 bytes)\n",
            "Collecting llama-index-embeddings-openai==0.1.7\n",
            "  Downloading llama_index_embeddings_openai-0.1.7-py3-none-any.whl.metadata (603 bytes)\n",
            "Collecting llama-index-agent-openai==0.2.2\n",
            "  Downloading llama_index_agent_openai-0.2.2-py3-none-any.whl.metadata (677 bytes)\n",
            "Requirement already satisfied: nest-asyncio==1.6.0 in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.23.2) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.23.2) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai==1.23.2)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.23.2) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.23.2) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.23.2) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai==1.23.2) (4.12.2)\n",
            "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index==0.10.27)\n",
            "  Downloading llama_index_cli-0.1.13-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama-index==0.10.27)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index==0.10.27)\n",
            "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index==0.10.27)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.1.8-py3-none-any.whl.metadata (728 bytes)\n",
            "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index==0.10.27)\n",
            "  Downloading llama_index_program_openai-0.1.7-py3-none-any.whl.metadata (760 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index==0.10.27)\n",
            "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata (785 bytes)\n",
            "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index==0.10.27)\n",
            "  Downloading llama_index_readers_file-0.1.31-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama-index==0.10.27)\n",
            "  Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.27) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.27) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.27) (3.9.5)\n",
            "Collecting dataclasses-json (from llama-index-core==0.10.27)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core==0.10.27)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core==0.10.27)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.27) (2024.6.1)\n",
            "Collecting llamaindex-py-client<0.2.0,>=0.1.16 (from llama-index-core==0.10.27)\n",
            "  Downloading llamaindex_py_client-0.1.19-py3-none-any.whl.metadata (760 bytes)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.27) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.27) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.27) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.27) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.27) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.27) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.27) (8.5.0)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core==0.10.27)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core==0.10.27)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.27) (1.14.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.27) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.27) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.27) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.27) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.27) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.27) (4.0.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.23.2) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.23.2) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.23.2) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai==1.23.2)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.23.2)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "INFO: pip is looking at multiple versions of llama-index-program-openai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index==0.10.27)\n",
            "  Downloading llama_index_program_openai-0.1.6-py3-none-any.whl.metadata (715 bytes)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.27) (4.12.3)\n",
            "INFO: pip is looking at multiple versions of llama-index-readers-file to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index==0.10.27)\n",
            "  Downloading llama_index_readers_file-0.1.30-py3-none-any.whl.metadata (5.4 kB)\n",
            "  Downloading llama_index_readers_file-0.1.29-py3-none-any.whl.metadata (5.4 kB)\n",
            "  Downloading llama_index_readers_file-0.1.28-py3-none-any.whl.metadata (5.4 kB)\n",
            "  Downloading llama_index_readers_file-0.1.27-py3-none-any.whl.metadata (5.4 kB)\n",
            "  Downloading llama_index_readers_file-0.1.26-py3-none-any.whl.metadata (5.4 kB)\n",
            "  Downloading llama_index_readers_file-0.1.25-py3-none-any.whl.metadata (5.4 kB)\n",
            "  Downloading llama_index_readers_file-0.1.23-py3-none-any.whl.metadata (5.4 kB)\n",
            "INFO: pip is still looking at multiple versions of llama-index-readers-file to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading llama_index_readers_file-0.1.22-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.27)\n",
            "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.27)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.27)\n",
            "  Downloading llama_parse-0.4.9-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.27) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.27) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.27) (2024.5.15)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.23.2) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.23.2) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core==0.10.27) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core==0.10.27) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.27) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core==0.10.27)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core==0.10.27)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.27) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.27) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core==0.10.27) (2024.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.27) (2.5)\n",
            "INFO: pip is looking at multiple versions of llama-parse to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.27)\n",
            "  Downloading llama_parse-0.4.8-py3-none-any.whl.metadata (4.4 kB)\n",
            "  Downloading llama_parse-0.4.7-py3-none-any.whl.metadata (4.4 kB)\n",
            "  Downloading llama_parse-0.4.6-py3-none-any.whl.metadata (4.4 kB)\n",
            "  Downloading llama_parse-0.4.5-py3-none-any.whl.metadata (4.4 kB)\n",
            "  Downloading llama_parse-0.4.4-py3-none-any.whl.metadata (3.5 kB)\n",
            "  Downloading llama_parse-0.4.3-py3-none-any.whl.metadata (3.5 kB)\n",
            "  Downloading llama_parse-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "INFO: pip is still looking at multiple versions of llama-parse to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading llama_parse-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "  Downloading llama_parse-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core==0.10.27) (24.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core==0.10.27) (1.16.0)\n",
            "Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Downloading openai-1.23.2-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index-0.10.27-py3-none-any.whl (6.9 kB)\n",
            "Downloading llama_index_core-0.10.27-py3-none-any.whl (15.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_llms_openai-0.1.15-py3-none-any.whl (10 kB)\n",
            "Downloading llama_index_embeddings_openai-0.1.7-py3-none-any.whl (6.0 kB)\n",
            "Downloading llama_index_agent_openai-0.2.2-py3-none-any.whl (12 kB)\n",
            "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_cli-0.1.13-py3-none-any.whl (27 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl (6.7 kB)\n",
            "Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_multi_modal_llms_openai-0.1.8-py3-none-any.whl (5.9 kB)\n",
            "Downloading llama_index_program_openai-0.1.6-py3-none-any.whl (5.2 kB)\n",
            "Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
            "Downloading llama_index_readers_file-0.1.22-py3-none-any.whl (36 kB)\n",
            "Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl (2.5 kB)\n",
            "Downloading llamaindex_py_client-0.1.19-py3-none-any.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading llama_parse-0.4.0-py3-none-any.whl (7.0 kB)\n",
            "Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: striprtf, dirtyjson, python-dotenv, pypdf, mypy-extensions, marshmallow, h11, deprecated, typing-inspect, tiktoken, httpcore, httpx, dataclasses-json, openai, llamaindex-py-client, llama-index-legacy, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
            "Successfully installed dataclasses-json-0.6.7 deprecated-1.2.14 dirtyjson-1.0.8 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 llama-index-0.10.27 llama-index-agent-openai-0.2.2 llama-index-cli-0.1.13 llama-index-core-0.10.27 llama-index-embeddings-openai-0.1.7 llama-index-indices-managed-llama-cloud-0.1.6 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.15 llama-index-multi-modal-llms-openai-0.1.8 llama-index-program-openai-0.1.6 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.22 llama-index-readers-llama-parse-0.1.6 llama-parse-0.4.0 llamaindex-py-client-0.1.19 marshmallow-3.21.3 mypy-extensions-1.0.0 openai-1.23.2 pypdf-4.3.1 python-dotenv-1.0.0 striprtf-0.0.26 tiktoken-0.7.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip list"
      ],
      "metadata": {
        "id": "G6rNJHOe0cRI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1ce064a-45c2-47e2-836a-d3265a0ce283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                                 Version\n",
            "--------------------------------------- ---------------------\n",
            "absl-py                                 1.4.0\n",
            "accelerate                              0.32.1\n",
            "aiohttp                                 3.9.5\n",
            "aiosignal                               1.3.1\n",
            "alabaster                               0.7.16\n",
            "albucore                                0.0.12\n",
            "albumentations                          1.4.11\n",
            "altair                                  4.2.2\n",
            "annotated-types                         0.7.0\n",
            "anyio                                   3.7.1\n",
            "argon2-cffi                             23.1.0\n",
            "argon2-cffi-bindings                    21.2.0\n",
            "array_record                            0.5.1\n",
            "arviz                                   0.18.0\n",
            "asn1crypto                              1.5.1\n",
            "astropy                                 6.1.2\n",
            "astropy-iers-data                       0.2024.7.22.0.34.13\n",
            "astunparse                              1.6.3\n",
            "async-timeout                           4.0.3\n",
            "atpublic                                4.1.0\n",
            "attrs                                   23.2.0\n",
            "audioread                               3.0.1\n",
            "autograd                                1.6.2\n",
            "Babel                                   2.15.0\n",
            "backcall                                0.2.0\n",
            "beautifulsoup4                          4.12.3\n",
            "bidict                                  0.23.1\n",
            "bigframes                               1.11.1\n",
            "bleach                                  6.1.0\n",
            "blinker                                 1.4\n",
            "blis                                    0.7.11\n",
            "blosc2                                  2.0.0\n",
            "bokeh                                   3.4.2\n",
            "bqplot                                  0.12.43\n",
            "branca                                  0.7.2\n",
            "build                                   1.2.1\n",
            "CacheControl                            0.14.0\n",
            "cachetools                              5.4.0\n",
            "catalogue                               2.0.10\n",
            "certifi                                 2024.7.4\n",
            "cffi                                    1.16.0\n",
            "chardet                                 5.2.0\n",
            "charset-normalizer                      3.3.2\n",
            "chex                                    0.1.86\n",
            "clarabel                                0.9.0\n",
            "click                                   8.1.7\n",
            "click-plugins                           1.1.1\n",
            "cligj                                   0.7.2\n",
            "cloudpathlib                            0.18.1\n",
            "cloudpickle                             2.2.1\n",
            "cmake                                   3.30.1\n",
            "cmdstanpy                               1.2.4\n",
            "colorcet                                3.1.0\n",
            "colorlover                              0.3.0\n",
            "colour                                  0.1.5\n",
            "community                               1.0.0b1\n",
            "confection                              0.1.5\n",
            "cons                                    0.4.6\n",
            "contextlib2                             21.6.0\n",
            "contourpy                               1.2.1\n",
            "cryptography                            42.0.8\n",
            "cuda-python                             12.2.1\n",
            "cudf-cu12                               24.4.1\n",
            "cufflinks                               0.17.3\n",
            "cupy-cuda12x                            12.2.0\n",
            "cvxopt                                  1.3.2\n",
            "cvxpy                                   1.5.2\n",
            "cycler                                  0.12.1\n",
            "cymem                                   2.0.8\n",
            "Cython                                  3.0.10\n",
            "dask                                    2024.7.1\n",
            "dataclasses-json                        0.6.7\n",
            "datascience                             0.17.6\n",
            "db-dtypes                               1.2.0\n",
            "dbus-python                             1.2.18\n",
            "debugpy                                 1.6.6\n",
            "decorator                               4.4.2\n",
            "defusedxml                              0.7.1\n",
            "Deprecated                              1.2.14\n",
            "dirtyjson                               1.0.8\n",
            "distributed                             2024.7.1\n",
            "distro                                  1.7.0\n",
            "dlib                                    19.24.4\n",
            "dm-tree                                 0.1.8\n",
            "docstring_parser                        0.16\n",
            "docutils                                0.18.1\n",
            "dopamine_rl                             4.0.9\n",
            "duckdb                                  0.10.3\n",
            "earthengine-api                         0.1.412\n",
            "easydict                                1.13\n",
            "ecos                                    2.0.14\n",
            "editdistance                            0.8.1\n",
            "eerepr                                  0.0.4\n",
            "en-core-web-sm                          3.7.1\n",
            "entrypoints                             0.4\n",
            "et-xmlfile                              1.1.0\n",
            "etils                                   1.7.0\n",
            "etuples                                 0.3.9\n",
            "eval_type_backport                      0.2.0\n",
            "exceptiongroup                          1.2.2\n",
            "fastai                                  2.7.15\n",
            "fastcore                                1.5.54\n",
            "fastdownload                            0.0.7\n",
            "fastjsonschema                          2.20.0\n",
            "fastprogress                            1.0.3\n",
            "fastrlock                               0.8.2\n",
            "filelock                                3.15.4\n",
            "fiona                                   1.9.6\n",
            "firebase-admin                          6.5.0\n",
            "Flask                                   2.2.5\n",
            "flatbuffers                             24.3.25\n",
            "flax                                    0.8.4\n",
            "folium                                  0.17.0\n",
            "fonttools                               4.53.1\n",
            "frozendict                              2.4.4\n",
            "frozenlist                              1.4.1\n",
            "fsspec                                  2024.6.1\n",
            "future                                  1.0.0\n",
            "gast                                    0.6.0\n",
            "gcsfs                                   2024.6.1\n",
            "GDAL                                    3.6.4\n",
            "gdown                                   5.1.0\n",
            "geemap                                  0.33.1\n",
            "gensim                                  4.3.3\n",
            "geocoder                                1.38.1\n",
            "geographiclib                           2.0\n",
            "geopandas                               0.14.4\n",
            "geopy                                   2.4.1\n",
            "gin-config                              0.5.0\n",
            "glob2                                   0.7\n",
            "google                                  2.0.3\n",
            "google-ai-generativelanguage            0.6.6\n",
            "google-api-core                         2.19.1\n",
            "google-api-python-client                2.137.0\n",
            "google-auth                             2.27.0\n",
            "google-auth-httplib2                    0.2.0\n",
            "google-auth-oauthlib                    1.2.1\n",
            "google-cloud-aiplatform                 1.59.0\n",
            "google-cloud-bigquery                   3.25.0\n",
            "google-cloud-bigquery-connection        1.15.4\n",
            "google-cloud-bigquery-storage           2.25.0\n",
            "google-cloud-bigtable                   2.25.0\n",
            "google-cloud-core                       2.4.1\n",
            "google-cloud-datastore                  2.19.0\n",
            "google-cloud-firestore                  2.16.1\n",
            "google-cloud-functions                  1.16.4\n",
            "google-cloud-iam                        2.15.1\n",
            "google-cloud-language                   2.13.4\n",
            "google-cloud-pubsub                     2.22.0\n",
            "google-cloud-resource-manager           1.12.4\n",
            "google-cloud-storage                    2.8.0\n",
            "google-cloud-translate                  3.15.4\n",
            "google-colab                            1.0.0\n",
            "google-crc32c                           1.5.0\n",
            "google-generativeai                     0.7.2\n",
            "google-pasta                            0.2.0\n",
            "google-resumable-media                  2.7.1\n",
            "googleapis-common-protos                1.63.2\n",
            "googledrivedownloader                   0.4\n",
            "graphviz                                0.20.3\n",
            "greenlet                                3.0.3\n",
            "grpc-google-iam-v1                      0.13.1\n",
            "grpcio                                  1.64.1\n",
            "grpcio-status                           1.48.2\n",
            "gspread                                 6.0.2\n",
            "gspread-dataframe                       3.3.1\n",
            "gym                                     0.25.2\n",
            "gym-notices                             0.0.8\n",
            "h11                                     0.14.0\n",
            "h5netcdf                                1.3.0\n",
            "h5py                                    3.11.0\n",
            "holidays                                0.53\n",
            "holoviews                               1.18.3\n",
            "html5lib                                1.1\n",
            "httpcore                                1.0.5\n",
            "httpimport                              1.3.1\n",
            "httplib2                                0.22.0\n",
            "httpx                                   0.27.0\n",
            "huggingface-hub                         0.23.5\n",
            "humanize                                4.10.0\n",
            "hyperopt                                0.2.7\n",
            "ibis-framework                          8.0.0\n",
            "idna                                    3.7\n",
            "imageio                                 2.34.2\n",
            "imageio-ffmpeg                          0.5.1\n",
            "imagesize                               1.4.1\n",
            "imbalanced-learn                        0.12.3\n",
            "imgaug                                  0.4.0\n",
            "immutabledict                           4.2.0\n",
            "importlib_metadata                      8.1.0\n",
            "importlib_resources                     6.4.0\n",
            "imutils                                 0.5.4\n",
            "inflect                                 7.3.1\n",
            "iniconfig                               2.0.0\n",
            "intel-cmplr-lib-ur                      2024.2.0\n",
            "intel-openmp                            2024.2.0\n",
            "ipyevents                               2.0.2\n",
            "ipyfilechooser                          0.6.0\n",
            "ipykernel                               5.5.6\n",
            "ipyleaflet                              0.18.2\n",
            "ipyparallel                             8.8.0\n",
            "ipython                                 7.34.0\n",
            "ipython-genutils                        0.2.0\n",
            "ipython-sql                             0.5.0\n",
            "ipytree                                 0.2.2\n",
            "ipywidgets                              7.7.1\n",
            "itsdangerous                            2.2.0\n",
            "jax                                     0.4.26\n",
            "jaxlib                                  0.4.26+cuda12.cudnn89\n",
            "jeepney                                 0.7.1\n",
            "jellyfish                               1.0.4\n",
            "jieba                                   0.42.1\n",
            "Jinja2                                  3.1.4\n",
            "joblib                                  1.4.2\n",
            "jsonpickle                              3.2.2\n",
            "jsonschema                              4.23.0\n",
            "jsonschema-specifications               2023.12.1\n",
            "jupyter-client                          6.1.12\n",
            "jupyter-console                         6.1.0\n",
            "jupyter_core                            5.7.2\n",
            "jupyter-server                          1.24.0\n",
            "jupyterlab_pygments                     0.3.0\n",
            "jupyterlab_widgets                      3.0.11\n",
            "kaggle                                  1.6.14\n",
            "kagglehub                               0.2.8\n",
            "keras                                   2.15.0\n",
            "keyring                                 23.5.0\n",
            "kiwisolver                              1.4.5\n",
            "langcodes                               3.4.0\n",
            "language_data                           1.2.0\n",
            "launchpadlib                            1.10.16\n",
            "lazr.restfulclient                      0.14.4\n",
            "lazr.uri                                1.0.6\n",
            "lazy_loader                             0.4\n",
            "libclang                                18.1.1\n",
            "librosa                                 0.10.2.post1\n",
            "lightgbm                                4.4.0\n",
            "linkify-it-py                           2.0.3\n",
            "llama-index                             0.10.27\n",
            "llama-index-agent-openai                0.2.2\n",
            "llama-index-cli                         0.1.13\n",
            "llama-index-core                        0.10.27\n",
            "llama-index-embeddings-openai           0.1.7\n",
            "llama-index-indices-managed-llama-cloud 0.1.6\n",
            "llama-index-legacy                      0.9.48\n",
            "llama-index-llms-openai                 0.1.15\n",
            "llama-index-multi-modal-llms-openai     0.1.8\n",
            "llama-index-program-openai              0.1.6\n",
            "llama-index-question-gen-openai         0.1.3\n",
            "llama-index-readers-file                0.1.22\n",
            "llama-index-readers-llama-parse         0.1.6\n",
            "llama-parse                             0.4.0\n",
            "llamaindex-py-client                    0.1.19\n",
            "llvmlite                                0.43.0\n",
            "locket                                  1.0.0\n",
            "logical-unification                     0.4.6\n",
            "lxml                                    4.9.4\n",
            "malloy                                  2024.1089\n",
            "marisa-trie                             1.2.0\n",
            "Markdown                                3.6\n",
            "markdown-it-py                          3.0.0\n",
            "MarkupSafe                              2.1.5\n",
            "marshmallow                             3.21.3\n",
            "matplotlib                              3.7.1\n",
            "matplotlib-inline                       0.1.7\n",
            "matplotlib-venn                         0.11.10\n",
            "mdit-py-plugins                         0.4.1\n",
            "mdurl                                   0.1.2\n",
            "miniKanren                              1.0.3\n",
            "missingno                               0.5.2\n",
            "mistune                                 0.8.4\n",
            "mizani                                  0.9.3\n",
            "mkl                                     2024.2.0\n",
            "ml-dtypes                               0.2.0\n",
            "mlxtend                                 0.23.1\n",
            "more-itertools                          10.3.0\n",
            "moviepy                                 1.0.3\n",
            "mpmath                                  1.3.0\n",
            "msgpack                                 1.0.8\n",
            "multidict                               6.0.5\n",
            "multipledispatch                        1.0.0\n",
            "multitasking                            0.0.11\n",
            "murmurhash                              1.0.10\n",
            "music21                                 9.1.0\n",
            "mypy-extensions                         1.0.0\n",
            "natsort                                 8.4.0\n",
            "nbclassic                               1.1.0\n",
            "nbclient                                0.10.0\n",
            "nbconvert                               6.5.4\n",
            "nbformat                                5.10.4\n",
            "nest-asyncio                            1.6.0\n",
            "networkx                                3.3\n",
            "nibabel                                 5.0.1\n",
            "nltk                                    3.8.1\n",
            "notebook                                6.5.5\n",
            "notebook_shim                           0.2.4\n",
            "numba                                   0.60.0\n",
            "numexpr                                 2.10.1\n",
            "numpy                                   1.25.2\n",
            "nvtx                                    0.2.10\n",
            "oauth2client                            4.1.3\n",
            "oauthlib                                3.2.2\n",
            "openai                                  1.23.2\n",
            "opencv-contrib-python                   4.10.0.84\n",
            "opencv-python                           4.10.0.84\n",
            "opencv-python-headless                  4.10.0.84\n",
            "openpyxl                                3.1.5\n",
            "opt-einsum                              3.3.0\n",
            "optax                                   0.2.2\n",
            "orbax-checkpoint                        0.4.4\n",
            "osqp                                    0.6.7.post0\n",
            "packaging                               24.1\n",
            "pandas                                  2.0.3\n",
            "pandas-datareader                       0.10.0\n",
            "pandas-gbq                              0.19.2\n",
            "pandas-stubs                            2.0.3.230814\n",
            "pandocfilters                           1.5.1\n",
            "panel                                   1.4.4\n",
            "param                                   2.1.1\n",
            "parso                                   0.8.4\n",
            "parsy                                   2.1\n",
            "partd                                   1.4.2\n",
            "pathlib                                 1.0.1\n",
            "patsy                                   0.5.6\n",
            "peewee                                  3.17.6\n",
            "pexpect                                 4.9.0\n",
            "pickleshare                             0.7.5\n",
            "Pillow                                  9.4.0\n",
            "pip                                     24.1.2\n",
            "pip-tools                               7.4.1\n",
            "platformdirs                            4.2.2\n",
            "plotly                                  5.15.0\n",
            "plotnine                                0.12.4\n",
            "pluggy                                  1.5.0\n",
            "polars                                  0.20.2\n",
            "pooch                                   1.8.2\n",
            "portpicker                              1.5.2\n",
            "prefetch_generator                      1.0.3\n",
            "preshed                                 3.0.9\n",
            "prettytable                             3.10.2\n",
            "proglog                                 0.1.10\n",
            "progressbar2                            4.2.0\n",
            "prometheus_client                       0.20.0\n",
            "promise                                 2.3\n",
            "prompt_toolkit                          3.0.47\n",
            "prophet                                 1.1.5\n",
            "proto-plus                              1.24.0\n",
            "protobuf                                3.20.3\n",
            "psutil                                  5.9.5\n",
            "psycopg2                                2.9.9\n",
            "ptyprocess                              0.7.0\n",
            "py-cpuinfo                              9.0.0\n",
            "py4j                                    0.10.9.7\n",
            "pyarrow                                 14.0.2\n",
            "pyarrow-hotfix                          0.6\n",
            "pyasn1                                  0.6.0\n",
            "pyasn1_modules                          0.4.0\n",
            "pycocotools                             2.0.8\n",
            "pycparser                               2.22\n",
            "pydantic                                2.8.2\n",
            "pydantic_core                           2.20.1\n",
            "pydata-google-auth                      1.8.2\n",
            "pydot                                   1.4.2\n",
            "pydot-ng                                2.0.0\n",
            "pydotplus                               2.0.2\n",
            "PyDrive                                 1.3.1\n",
            "PyDrive2                                1.6.3\n",
            "pyerfa                                  2.0.1.4\n",
            "pygame                                  2.6.0\n",
            "Pygments                                2.16.1\n",
            "PyGObject                               3.42.1\n",
            "PyJWT                                   2.8.0\n",
            "pymc                                    5.10.4\n",
            "pymystem3                               0.2.0\n",
            "pynvjitlink-cu12                        0.3.0\n",
            "PyOpenGL                                3.1.7\n",
            "pyOpenSSL                               24.2.1\n",
            "pyparsing                               3.1.2\n",
            "pypdf                                   4.3.1\n",
            "pyperclip                               1.9.0\n",
            "pyproj                                  3.6.1\n",
            "pyproject_hooks                         1.1.0\n",
            "pyshp                                   2.3.1\n",
            "PySocks                                 1.7.1\n",
            "pytensor                                2.18.6\n",
            "pytest                                  7.4.4\n",
            "python-apt                              2.4.0\n",
            "python-box                              7.2.0\n",
            "python-dateutil                         2.8.2\n",
            "python-dotenv                           1.0.0\n",
            "python-louvain                          0.16\n",
            "python-slugify                          8.0.4\n",
            "python-utils                            3.8.2\n",
            "pytz                                    2024.1\n",
            "pyviz_comms                             3.0.2\n",
            "PyYAML                                  6.0.1\n",
            "pyzmq                                   24.0.1\n",
            "qdldl                                   0.1.7.post4\n",
            "ratelim                                 0.1.6\n",
            "referencing                             0.35.1\n",
            "regex                                   2024.5.15\n",
            "requests                                2.31.0\n",
            "requests-oauthlib                       1.3.1\n",
            "requirements-parser                     0.9.0\n",
            "rich                                    13.7.1\n",
            "rmm-cu12                                24.4.0\n",
            "rpds-py                                 0.19.0\n",
            "rpy2                                    3.4.2\n",
            "rsa                                     4.9\n",
            "safetensors                             0.4.3\n",
            "scikit-image                            0.23.2\n",
            "scikit-learn                            1.3.2\n",
            "scipy                                   1.13.1\n",
            "scooby                                  0.10.0\n",
            "scs                                     3.2.6\n",
            "seaborn                                 0.13.1\n",
            "SecretStorage                           3.3.1\n",
            "Send2Trash                              1.8.3\n",
            "sentencepiece                           0.1.99\n",
            "setuptools                              71.0.4\n",
            "shapely                                 2.0.5\n",
            "shellingham                             1.5.4\n",
            "simple_parsing                          0.1.5\n",
            "six                                     1.16.0\n",
            "sklearn-pandas                          2.2.0\n",
            "smart-open                              7.0.4\n",
            "sniffio                                 1.3.1\n",
            "snowballstemmer                         2.2.0\n",
            "snowflake-connector-python              3.11.0\n",
            "sortedcontainers                        2.4.0\n",
            "soundfile                               0.12.1\n",
            "soupsieve                               2.5\n",
            "soxr                                    0.3.7\n",
            "spacy                                   3.7.5\n",
            "spacy-legacy                            3.0.12\n",
            "spacy-loggers                           1.0.5\n",
            "Sphinx                                  5.0.2\n",
            "sphinxcontrib-applehelp                 1.0.8\n",
            "sphinxcontrib-devhelp                   1.0.6\n",
            "sphinxcontrib-htmlhelp                  2.0.6\n",
            "sphinxcontrib-jsmath                    1.0.1\n",
            "sphinxcontrib-qthelp                    1.0.8\n",
            "sphinxcontrib-serializinghtml           1.1.10\n",
            "SQLAlchemy                              2.0.31\n",
            "sqlglot                                 20.11.0\n",
            "sqlparse                                0.5.1\n",
            "srsly                                   2.4.8\n",
            "stanio                                  0.5.1\n",
            "statsmodels                             0.14.2\n",
            "StrEnum                                 0.4.15\n",
            "striprtf                                0.0.26\n",
            "sympy                                   1.13.1\n",
            "tables                                  3.8.0\n",
            "tabulate                                0.9.0\n",
            "tbb                                     2021.13.0\n",
            "tblib                                   3.0.0\n",
            "tenacity                                8.5.0\n",
            "tensorboard                             2.15.2\n",
            "tensorboard-data-server                 0.7.2\n",
            "tensorflow                              2.15.0\n",
            "tensorflow-datasets                     4.9.6\n",
            "tensorflow-estimator                    2.15.0\n",
            "tensorflow-gcs-config                   2.15.0\n",
            "tensorflow-hub                          0.16.1\n",
            "tensorflow-io-gcs-filesystem            0.37.1\n",
            "tensorflow-metadata                     1.15.0\n",
            "tensorflow-probability                  0.23.0\n",
            "tensorstore                             0.1.45\n",
            "termcolor                               2.4.0\n",
            "terminado                               0.18.1\n",
            "text-unidecode                          1.3\n",
            "textblob                                0.17.1\n",
            "tf_keras                                2.15.1\n",
            "tf-slim                                 1.1.0\n",
            "thinc                                   8.2.5\n",
            "threadpoolctl                           3.5.0\n",
            "tifffile                                2024.7.21\n",
            "tiktoken                                0.7.0\n",
            "tinycss2                                1.3.0\n",
            "tokenizers                              0.19.1\n",
            "toml                                    0.10.2\n",
            "tomli                                   2.0.1\n",
            "tomlkit                                 0.13.0\n",
            "toolz                                   0.12.1\n",
            "torch                                   2.3.1+cu121\n",
            "torchaudio                              2.3.1+cu121\n",
            "torchsummary                            1.5.1\n",
            "torchtext                               0.18.0\n",
            "torchvision                             0.18.1+cu121\n",
            "tornado                                 6.3.3\n",
            "tqdm                                    4.66.4\n",
            "traitlets                               5.7.1\n",
            "traittypes                              0.2.1\n",
            "transformers                            4.42.4\n",
            "triton                                  2.3.1\n",
            "tweepy                                  4.14.0\n",
            "typeguard                               4.3.0\n",
            "typer                                   0.12.3\n",
            "types-pytz                              2024.1.0.20240417\n",
            "types-setuptools                        71.1.0.20240724\n",
            "typing_extensions                       4.12.2\n",
            "typing-inspect                          0.9.0\n",
            "tzdata                                  2024.1\n",
            "tzlocal                                 5.2\n",
            "uc-micro-py                             1.0.3\n",
            "uritemplate                             4.1.1\n",
            "urllib3                                 2.0.7\n",
            "vega-datasets                           0.9.0\n",
            "wadllib                                 1.3.6\n",
            "wasabi                                  1.1.3\n",
            "wcwidth                                 0.2.13\n",
            "weasel                                  0.4.1\n",
            "webcolors                               24.6.0\n",
            "webencodings                            0.5.1\n",
            "websocket-client                        1.8.0\n",
            "Werkzeug                                3.0.3\n",
            "wheel                                   0.43.0\n",
            "widgetsnbextension                      3.6.7\n",
            "wordcloud                               1.9.3\n",
            "wrapt                                   1.14.1\n",
            "xarray                                  2024.6.0\n",
            "xarray-einstats                         0.7.0\n",
            "xgboost                                 2.1.0\n",
            "xlrd                                    2.0.1\n",
            "xyzservices                             2024.6.0\n",
            "yarl                                    1.9.4\n",
            "yellowbrick                             1.5\n",
            "yfinance                                0.2.41\n",
            "zict                                    3.0.0\n",
            "zipp                                    3.19.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ./.env\n",
        "OPENAI_API_KEY=sk-GUktlQ4YGz8DdZ1D5f02A83836444b4dAdC7D5F9BcFeFf6d\n",
        "# replace https://api.openai.com/v1 with API transit address\n",
        "OPENAI_BASE_URL=https://pro.aiskt.com/v1"
      ],
      "metadata": {
        "id": "jpSGN2ZFLoLc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28de246f-2598-44e4-818d-e035252929c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing ./.env\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "def get_openai_api_key():\n",
        "    _ = load_dotenv(find_dotenv())\n",
        "    return os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "def get_openai_base_url():\n",
        "    _ = load_dotenv(find_dotenv())\n",
        "    return os.getenv(\"OPENAI_BASE_URL\")\n",
        "\n",
        "# assign corresponding value to api_key before invoking OpenAI(), once setup here, all the following calling from\n",
        "# other frameworks like LlamaIndex and Trulens will inherit and don't need to config for the same\n",
        "import openai\n",
        "openai.api_key = get_openai_api_key()\n",
        "openai.base_url = get_openai_base_url()\n",
        "#OPENAI_API_KEY = get_openai_api_key()\n",
        "#OPENAI_BASE_URL = get_openai_base_url()\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "TbYO1t3xLxv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Router Query Engines of Summary Index and Vector Index"
      ],
      "metadata": {
        "id": "X-NhSr1mLyp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.core import Settings\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.core import SummaryIndex, VectorStoreIndex\n",
        "from llama_index.core.tools import QueryEngineTool\n",
        "from llama_index.core.query_engine.router_query_engine import RouterQueryEngine\n",
        "from llama_index.core.selectors import LLMSingleSelector\n",
        "\n",
        "def get_router_query_engine(\n",
        "    file_path: str,\n",
        "    llm = None,\n",
        "    embed_model = None,\n",
        "):\n",
        "    llm = llm or OpenAI(model=\"gpt-3.5-turbo\")\n",
        "    embed_model = embed_model or OpenAIEmbedding(model=\"text-embedding-ada-002\")\n",
        "\n",
        "    documents = SimpleDirectoryReader(input_files=[file_path]).load_data()\n",
        "\n",
        "    splitter = SentenceSplitter(chunk_size=1024)\n",
        "    nodes = splitter.get_nodes_from_documents(documents)\n",
        "\n",
        "    # try to avoid the following issue: 'NoneType' object is not iterable\n",
        "    '''\n",
        "    /usr/local/lib/python3.10/dist-packages/openai/resources/embeddings.py in parser(obj)\n",
        "    --> 101 for embedding in obj.data:\n",
        "        102     data = cast(object, embedding.embedding)\n",
        "    TypeError: 'NoneType' object is not iterable\n",
        "    '''\n",
        "\n",
        "    summary_index = SummaryIndex(\n",
        "        nodes,\n",
        "        #embed_model=embed_model,\n",
        "    )\n",
        "    vector_index = VectorStoreIndex(\n",
        "        nodes,\n",
        "        #embed_model=embed_model,\n",
        "    )\n",
        "\n",
        "    summary_query_engine = summary_index.as_query_engine(\n",
        "        response_mode=\"tree_summarize\",\n",
        "        use_async=True,\n",
        "        llm=llm,\n",
        "    )\n",
        "    vector_query_engine = vector_index.as_query_engine(\n",
        "        llm=llm,\n",
        "    )\n",
        "\n",
        "    summary_tool = QueryEngineTool.from_defaults(\n",
        "        query_engine=summary_query_engine,\n",
        "        description=(\n",
        "            \"Useful for summarization questions related to MetaGPT\"\n",
        "        ),\n",
        "    )\n",
        "    vector_tool = QueryEngineTool.from_defaults(\n",
        "        query_engine=vector_query_engine,\n",
        "        description=(\n",
        "            \"Useful for retrieving specific context or particular content in detail from the paper of MetaGPT\"\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    query_engine = RouterQueryEngine(\n",
        "        selector=LLMSingleSelector.from_defaults(),\n",
        "        query_engine_tools=[\n",
        "            summary_tool,\n",
        "            vector_tool,\n",
        "        ],\n",
        "        verbose=True,\n",
        "    )\n",
        "    return query_engine"
      ],
      "metadata": {
        "id": "z9Tt1URXLyA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import Settings\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "\n",
        "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
        "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")"
      ],
      "metadata": {
        "id": "TqLv867IMJAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "\n",
        "documents = SimpleDirectoryReader(\n",
        "    input_files=[\"Paper-METAGPT_META_PROGRAMMING_FOR_A_MULTI-AGENT_COLLABORATIVE_FRAMEWORK.pdf\"],\n",
        ").load_data()\n",
        "\n",
        "splitter = SentenceSplitter(chunk_size=1024)\n",
        "nodes = splitter.get_nodes_from_documents(documents)"
      ],
      "metadata": {
        "id": "UNeoUK8UMJGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SummaryIndex, VectorStoreIndex\n",
        "from llama_index.core.tools import QueryEngineTool\n",
        "\n",
        "summary_index = SummaryIndex(nodes)\n",
        "vector_index = VectorStoreIndex(nodes)\n",
        "\n",
        "summary_query_engine = summary_index.as_query_engine(\n",
        "    response_mode=\"tree_summarize\",\n",
        "    use_async=True,\n",
        ")\n",
        "vector_query_engine = vector_index.as_query_engine()\n",
        "\n",
        "summary_tool = QueryEngineTool.from_defaults(\n",
        "    query_engine=summary_query_engine,\n",
        "    description=(\n",
        "        \"Useful for summarization questions related to MetaGPT\"\n",
        "    ),\n",
        ")\n",
        "vector_tool = QueryEngineTool.from_defaults(\n",
        "    query_engine=vector_query_engine,\n",
        "    description=(\n",
        "        \"Useful for retrieving specific context or particular content in detail from the paper of MetaGPT\"\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "tWPTQGlRMI56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.query_engine.router_query_engine import RouterQueryEngine\n",
        "from llama_index.core.selectors import LLMSingleSelector\n",
        "\n",
        "query_engine = RouterQueryEngine(\n",
        "    selector=LLMSingleSelector.from_defaults(),\n",
        "    query_engine_tools=[\n",
        "        summary_tool,\n",
        "        vector_tool,\n",
        "    ],\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "response = query_engine.query(\n",
        "    \"What is the summary of the document?\"\n",
        ")\n",
        "print(str(response))\n",
        "print(len(response.source_nodes))\n",
        "\n",
        "response = query_engine.query(\n",
        "    \"How do agents share information in detail with other agents?\"\n",
        ")\n",
        "print(str(response))\n",
        "print(len(response.source_nodes))"
      ],
      "metadata": {
        "id": "GXzUB2aAMtLW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a71cb579-02b5-4d8d-cffc-68b59853d2c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;3;38;5;200mSelecting query engine 0: The document is likely a summary of MetaGPT, making choice 1 the most relevant option..\n",
            "\u001b[0mThe document introduces MetaGPT, a meta-programming framework for multi-agent collaboration in software development. It emphasizes the use of Standardized Operating Procedures (SOPs) to enhance efficiency and reduce errors among agents. MetaGPT assigns specific roles to agents, streamlining workflows and improving code generation quality. The framework incorporates structured communication interfaces, a publish-subscribe mechanism, and an executable feedback mechanism to facilitate information exchange and iterative code quality improvement. Experimental results demonstrate MetaGPT's effectiveness in generating software solutions, outperforming previous methods in code generation tasks. The framework also explores self-improvement mechanisms, role specialization, and the impact of different roles on final results. Additionally, it addresses challenges such as efficient context use, reducing hallucinations, handling information overload, and ensuring transparency and accountability in multi-agent collaborative programming.\n",
            "34\n",
            "\u001b[1;3;38;5;200mSelecting query engine 1: This choice is more relevant as it specifically mentions retrieving specific context or particular content in detail, which aligns with sharing information in detail with other agents..\n",
            "\u001b[0mAgents share information by utilizing a shared message pool where they publish structured messages. This shared message pool allows all agents to exchange messages directly and access messages from other entities transparently. Agents can retrieve required information from the shared pool without the need to inquire about other agents individually. Additionally, agents can subscribe to relevant messages based on their role profiles, enabling them to extract information that is specifically relevant to their tasks and responsibilities.\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = get_router_query_engine(\"Paper-METAGPT_META_PROGRAMMING_FOR_A_MULTI-AGENT_COLLABORATIVE_FRAMEWORK.pdf\")\n",
        "\n",
        "response = query_engine.query(\n",
        "    \"Tell me about the ablation study results?\"\n",
        ")\n",
        "print(str(response))"
      ],
      "metadata": {
        "id": "QC-6mTWpM_Ma",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5306b170-5846-4c7b-9e80-7d481e3e1717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;3;38;5;200mSelecting query engine 1: Ablation study results typically involve specific details and context from the paper, which aligns with choice 2..\n",
            "\u001b[0mThe ablation study results provide insights into the impact of different components or features on the overall performance of a system. By systematically removing or disabling specific elements and observing how it affects the system's functionality, researchers can evaluate the significance of each component in achieving the desired outcomes. This analysis helps in understanding the contributions of individual parts and their collective effect on the system's performance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a Multi-document Agent"
      ],
      "metadata": {
        "id": "nuRnj1D_6UFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo\")"
      ],
      "metadata": {
        "id": "9g_1KDvODE-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAQ2z6113NfT"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, SummaryIndex\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.core.tools import FunctionTool, QueryEngineTool\n",
        "from llama_index.core.vector_stores import MetadataFilters, FilterCondition\n",
        "from llama_index.core.llms import ChatMessage\n",
        "from typing import List, Optional\n",
        "\n",
        "def get_doc_tools(\n",
        "    file_path: str,\n",
        "    name: str,\n",
        ") -> str:\n",
        "    documents = SimpleDirectoryReader(input_files=[file_path]).load_data()\n",
        "\n",
        "    splitter = SentenceSplitter(chunk_size=1024)\n",
        "    nodes = splitter.get_nodes_from_documents(documents)\n",
        "\n",
        "    vector_index = VectorStoreIndex(nodes)\n",
        "\n",
        "    # vector_query is used to answer questions over a given paper, always leave page_numbers as None unless there is\n",
        "    # a specific page you want to search for\n",
        "    def vector_query(\n",
        "        query: str,\n",
        "        page_numbers: Optional[List[str]] = None,\n",
        "    ) -> str:\n",
        "        page_numbers = page_numbers or []\n",
        "        metadata_dicts = [\n",
        "            {\"key\": \"page_label\", \"value\": p} for p in page_numbers\n",
        "        ]\n",
        "\n",
        "        query_engine = vector_index.as_query_engine(\n",
        "            similarity_top_k=2,\n",
        "            filters=MetadataFilters.from_dicts(\n",
        "                metadata_dicts,\n",
        "                condition=FilterCondition.OR,\n",
        "            ),\n",
        "        )\n",
        "        response = query_engine.query(query)\n",
        "\n",
        "        return response\n",
        "\n",
        "    # the tool name is expected a string with maximum length 64 of only alphabet and underscore, etc., here fetching\n",
        "    # the keywords from the long file name\n",
        "    messages = [\n",
        "        ChatMessage(\n",
        "            role=\"system\",\n",
        "            content=\"You're good at summarization. The user prompt is a paper name. Offer a best short version \\\n",
        "            according to the below rules: \\\n",
        "            1. Keep the first 3 words exactly same as the original paper name and remove the word paper \\\n",
        "            2. Reserve the keywords of the paper name especially describing the core concept \\\n",
        "            3. Only alphabet and underscore are allowed, truncate the tail if it exceeds 30 characters\",\n",
        "        ),\n",
        "        ChatMessage(role=\"user\", content=name),\n",
        "    ]\n",
        "    # assure naming conventions of the tool name by applying solid programming codes afterwards\n",
        "    short_name = str(llm.chat(messages).message.content).replace(\" \", \"_\")[:30]\n",
        "    print(\"Tool name: \" + short_name)\n",
        "\n",
        "    # FuntionTool allow users to easily convert a user-defined function into a tool, and when using an agent with\n",
        "    # function calling, the tool selected rely strongly on the name and description of the tools, therefore carefully\n",
        "    # tuning these parameters can result in larges changes in how LLM calls the tools\n",
        "    # ref: https://docs.llamaindex.ai/en/stable/module_guides/deploying/agents/tools/\n",
        "    vector_query_tool = FunctionTool.from_defaults(\n",
        "        name=f\"vector_tool_{short_name}\",\n",
        "        fn=vector_query,\n",
        "        description=(\n",
        "            f\"Useful for retrieving specific context or particular content in detail from the paper of {name}\"\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    summary_index = SummaryIndex(nodes)\n",
        "    summary_query_engine = summary_index.as_query_engine(\n",
        "        response_mode=\"tree_summarize\",\n",
        "        use_async=True,\n",
        "    )\n",
        "    summary_tool = QueryEngineTool.from_defaults(\n",
        "        name=f\"summary_tool_{short_name}\",\n",
        "        query_engine=summary_query_engine,\n",
        "        description=(\n",
        "            f\"Useful for summarization questions related to {name}\"\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    return vector_query_tool, summary_tool"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "urls = [\n",
        "    \"https://openreview.net/pdf?id=VtmBAGCN7o\",\n",
        "    \"https://openreview.net/pdf?id=6PmJoRfdaK\",\n",
        "    \"https://openreview.net/pdf?id=hSyW5go0v8\",\n",
        "]\n",
        "\n",
        "papers = [\n",
        "    \"Paper-METAGPT_META_PROGRAMMING_FOR_A_MULTI-AGENT_COLLABORATIVE_FRAMEWORK.pdf\",\n",
        "    \"Paper-LONGLORA_EFFICIENT_FINE-TUNING_OF_LONG-CONTEXT_LARGE_LANGUAGE_MODELS.pdf\",\n",
        "    \"Paper-SELF-RAG_LEARNING_TO_RETRIEVE_GENERATE_AND_CRITIQUE_THROUGH_SELF-REFLECTION.pdf\",\n",
        "]"
      ],
      "metadata": {
        "id": "5FIiohUJ6c6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "paper_to_tools_dict = {}\n",
        "for paper in papers:\n",
        "    print(f\"Getting tools for paper: {paper}\")\n",
        "\n",
        "    vector_tool, summary_tool = get_doc_tools(paper, Path(paper).stem)\n",
        "    paper_to_tools_dict[paper] = [vector_tool, summary_tool]\n",
        "\n",
        "initial_tools = [t for paper in papers for t in paper_to_tools_dict[paper]]\n",
        "len(initial_tools)"
      ],
      "metadata": {
        "id": "arjvYUOa6c3v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0f2bd03-3547-480a-bfc2-e69b9e5d60a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting tools for paper: Paper-METAGPT_META_PROGRAMMING_FOR_A_MULTI-AGENT_COLLABORATIVE_FRAMEWORK.pdf\n",
            "Tool name: METAGPT_META_PROGRAMMING_MULTI\n",
            "Getting tools for paper: Paper-LONGLORA_EFFICIENT_FINE-TUNING_OF_LONG-CONTEXT_LARGE_LANGUAGE_MODELS.pdf\n",
            "Tool name: LONGLO_EFFICIENT_FINE_TUNING\n",
            "Getting tools for paper: Paper-SELF-RAG_LEARNING_TO_RETRIEVE_GENERATE_AND_CRITIQUE_THROUGH_SELF-REFLECTION.pdf\n",
            "Tool name: SELF-RAG_LEARNING_RETRIEVE_GEN\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.agent import FunctionCallingAgentWorker\n",
        "from llama_index.core.agent import AgentRunner\n",
        "\n",
        "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
        "    initial_tools,\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        ")\n",
        "agent = AgentRunner(agent_worker)"
      ],
      "metadata": {
        "id": "L7n--SHQ6cxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.query(\n",
        "    \"Tell me about the evaluation dataset used in LongLoRA, and then tell me about the evaluation results\"\n",
        ")\n",
        "print(str(response), \"\\n\")\n",
        "response = agent.query(\n",
        "    \"Give me a summary of both Self-RAG and LongLoRA\"\n",
        ")\n",
        "print(str(response))"
      ],
      "metadata": {
        "id": "pGkrxQaC6cpC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54239c86-938b-4547-a04c-a7afe8c9567d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added user message to memory: Tell me about the evaluation dataset used in LongLoRA, and then tell me about the evaluation results\n",
            "=== Calling Function ===\n",
            "Calling function: vector_tool_LONGLO_EFFICIENT_FINE_TUNING with args: {\"query\": \"evaluation dataset\"}\n",
            "=== Calling Function ===\n",
            "Calling function: vector_tool_LONGLO_EFFICIENT_FINE_TUNING with args: {\"query\": \"evaluation results\"}\n",
            "assistant: The evaluation dataset used in LongLoRA is the PG19 test split. \n",
            "\n",
            "Regarding the evaluation results, the models in LongLoRA achieve better perplexity with longer context sizes. Increasing the context window size leads to a decrease in perplexity, demonstrating the effectiveness of the efficient fine-tuning method. The models also show promising results on extremely large context lengths. However, there is some perplexity degradation on small context sizes for the extended models. \n",
            "\n",
            "Added user message to memory: Give me a summary of both Self-RAG and LongLoRA\n",
            "=== Calling Function ===\n",
            "Calling function: summary_tool_SELF-RAG_LEARNING_RETRIEVE_GEN with args: {\"input\": \"Self-RAG\"}\n",
            "=== Calling Function ===\n",
            "Calling function: summary_tool_LONGLO_EFFICIENT_FINE_TUNING with args: {\"input\": \"LongLoRA\"}\n",
            "assistant: Self-RAG is a framework that enhances the quality and factuality of a large language model through retrieval and self-reflection. It involves training a critic model and a generator model, where the critic model evaluates retrieved passages and generated output using reflection tokens, while the generator model predicts the target output and reflection tokens. This approach allows the model to dynamically decide when to retrieve text passages and control its generation process using special tokens, leading to tailored behavior based on task requirements and significant performance improvements across various tasks compared to other language models and retrieval-augmented models.\n",
            "\n",
            "LongLoRA is an efficient method for extending the context sizes of pre-trained large language models with limited computation cost. It combines shifted sparse attention (S2-Attn) with LoRA to enable significant computation savings while maintaining performance. This approach allows for extending the context window of large language models efficiently, demonstrating strong empirical results on various tasks and models ranging from 7B to 70B.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "urls = [\n",
        "    \"https://openreview.net/pdf?id=VtmBAGCN7o\",\n",
        "    \"https://openreview.net/pdf?id=6PmJoRfdaK\",\n",
        "    \"https://openreview.net/pdf?id=LzPWWPAdY4\",\n",
        "    \"https://openreview.net/pdf?id=VTF8yNQM66\",\n",
        "    \"https://openreview.net/pdf?id=hSyW5go0v8\",\n",
        "    \"https://openreview.net/pdf?id=9WD9KwssyT\",\n",
        "    \"https://openreview.net/pdf?id=yV6fD7LYkF\",\n",
        "    \"https://openreview.net/pdf?id=hnrB5YHoYu\",\n",
        "    \"https://openreview.net/pdf?id=WbWtOYIzIK\",\n",
        "    \"https://openreview.net/pdf?id=c5pwL0Soay\",\n",
        "    \"https://openreview.net/pdf?id=TpD2aG1h0D\",\n",
        "]\n",
        "\n",
        "papers = [\n",
        "    \"Paper-METAGPT_META_PROGRAMMING_FOR_A_MULTI-AGENT_COLLABORATIVE_FRAMEWORK.pdf\",\n",
        "    \"Paper-LONGLORA_EFFICIENT_FINE-TUNING_OF_LONG-CONTEXT_LARGE_LANGUAGE_MODELS.pdf\",\n",
        "    \"Paper-LOFTQ_LORA-FINE-TUNING-AWARE_QUANTIZATION_FOR_LARGE_LANGUAGE_MODELS.pdf\",\n",
        "    \"Paper-SWE-BENCH_CAN_LANGUAGE_MODELS_RESOLVE_REAL-WORLD_GITHUB_ISSUES.pdf\",\n",
        "    \"Paper-SELF-RAG_LEARNING_TO_RETRIEVE_GENERATE_AND_CRITIQUE_THROUGH_SELF-REFLECTION.pdf\",\n",
        "    \"Paper-ZIPFORMER_A_FASTER_AND_BETTER_ENCODER_FOR_AUTOMATIC_SPEECH_RECOGNITION.pdf\",\n",
        "    \"Paper-VALUES_A_FRAMEWORK_FOR_SYSTEMATIC_VALIDATION_OF_UNCERTAINTY_ESTIMATION_IN_SEMANTIC_SEGMENTATION.pdf\",\n",
        "    \"Paper-FINETUNING_TEXT-TO-IMAGE_DIFFUSION_MODELS_FOR_FAIRNESS.pdf\",\n",
        "    \"Paper-KNOWLEDGE_CARD_FILLING_LLMS_KNOWLEDGE_GAPS_WITH_PLUG-IN_SPECIALIZED_LANGUAGE_MODELS.pdf\",\n",
        "    \"Paper-METRA_SCALABLE_UNSUPERVISED_RL_WITH_METRIC-AWARE_ABSTRACTION.pdf\",\n",
        "    \"Paper-META_CONTINUAL_LEARNING_REVISITED_IMPLICITLY_ENHANCING_ONLINE_HESSIAN_APPROXIMATION_VIA_VARIANCE_REDUCTION.pdf\",\n",
        "]"
      ],
      "metadata": {
        "id": "g5wLEU6f9e9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "paper_to_tools_dict = {}\n",
        "for paper in papers:\n",
        "    print(f\"Getting tools for paper: {paper}\")\n",
        "\n",
        "    vector_tool, summary_tool = get_doc_tools(paper, Path(paper).stem)\n",
        "    paper_to_tools_dict[paper] = [vector_tool, summary_tool]\n",
        "\n",
        "all_tools = [t for paper in papers for t in paper_to_tools_dict[paper]]\n",
        "len(all_tools)"
      ],
      "metadata": {
        "id": "aql6-o_19e5V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f8a5ebd-10e0-43b1-d02b-83a12bcd4f24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting tools for paper: Paper-METAGPT_META_PROGRAMMING_FOR_A_MULTI-AGENT_COLLABORATIVE_FRAMEWORK.pdf\n",
            "Tool name: METAGPT_META_PROGRAMMING_MULTI\n",
            "Getting tools for paper: Paper-LONGLORA_EFFICIENT_FINE-TUNING_OF_LONG-CONTEXT_LARGE_LANGUAGE_MODELS.pdf\n",
            "Tool name: LONGLO_EFFICIENT_FINE_TUNING\n",
            "Getting tools for paper: Paper-LOFTQ_LORA-FINE-TUNING-AWARE_QUANTIZATION_FOR_LARGE_LANGUAGE_MODELS.pdf\n",
            "Tool name: LOFTQ_LORA_FINE_TUNING_AWARE_Q\n",
            "Getting tools for paper: Paper-SWE-BENCH_CAN_LANGUAGE_MODELS_RESOLVE_REAL-WORLD_GITHUB_ISSUES.pdf\n",
            "Tool name: SWE_BENCH_CAN_LANGUAGE_MODELS\n",
            "Getting tools for paper: Paper-SELF-RAG_LEARNING_TO_RETRIEVE_GENERATE_AND_CRITIQUE_THROUGH_SELF-REFLECTION.pdf\n",
            "Tool name: SELF-RAG_LEARNING_RETRIEVE_GEN\n",
            "Getting tools for paper: Paper-ZIPFORMER_A_FASTER_AND_BETTER_ENCODER_FOR_AUTOMATIC_SPEECH_RECOGNITION.pdf\n",
            "Tool name: ZIPFORMER_A_FASTER_BETTER_ENCO\n",
            "Getting tools for paper: Paper-VALUES_A_FRAMEWORK_FOR_SYSTEMATIC_VALIDATION_OF_UNCERTAINTY_ESTIMATION_IN_SEMANTIC_SEGMENTATION.pdf\n",
            "Tool name: VALUES_A_FRAMEWORK_FOR_SYSTEMA\n",
            "Getting tools for paper: Paper-FINETUNING_TEXT-TO-IMAGE_DIFFUSION_MODELS_FOR_FAIRNESS.pdf\n",
            "Tool name: FINETUNING_TEXT_TO_IMAGE_DIFFU\n",
            "Getting tools for paper: Paper-KNOWLEDGE_CARD_FILLING_LLMS_KNOWLEDGE_GAPS_WITH_PLUG-IN_SPECIALIZED_LANGUAGE_MODELS.pdf\n",
            "Tool name: KNOWLEDGE_CARD_FILLING_LLMS_FI\n",
            "Getting tools for paper: Paper-METRA_SCALABLE_UNSUPERVISED_RL_WITH_METRIC-AWARE_ABSTRACTION.pdf\n",
            "Tool name: METRA_SCALABLE_UNSUPERVISED_RL\n",
            "Getting tools for paper: Paper-META_CONTINUAL_LEARNING_REVISITED_IMPLICITLY_ENHANCING_ONLINE_HESSIAN_APPROXIMATION_VIA_VARIANCE_REDUCTION.pdf\n",
            "Tool name: META_CONTINUAL_LEARNING_REVISI\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.core.objects import ObjectIndex\n",
        "\n",
        "obj_index = ObjectIndex.from_objects(\n",
        "    all_tools,\n",
        "    index_cls=VectorStoreIndex,\n",
        ")\n",
        "\n",
        "obj_retriever = obj_index.as_retriever(similarity_top_k=3)\n",
        "tools = obj_retriever.retrieve(\n",
        "    \"Tell me about the evaluation dataset used in MetaGPT and compare it against SWE-Bench, just the brief info is enough\"\n",
        ")\n",
        "for tool in tools:\n",
        "  print(tool.metadata)"
      ],
      "metadata": {
        "id": "QjUK5qRT9ezt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc06e93f-3120-4e96-dc2b-ba42b3c3aeae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ToolMetadata(description='Useful for summarization questions related to Paper-SWE-BENCH_CAN_LANGUAGE_MODELS_RESOLVE_REAL-WORLD_GITHUB_ISSUES', name='summary_tool_SWE_BENCH_CAN_LANGUAGE_MODELS', fn_schema=<class 'llama_index.core.tools.types.DefaultToolFnSchema'>)\n",
            "ToolMetadata(description='Useful for summarization questions related to Paper-METAGPT_META_PROGRAMMING_FOR_A_MULTI-AGENT_COLLABORATIVE_FRAMEWORK', name='summary_tool_METAGPT_META_PROGRAMMING_MULTI', fn_schema=<class 'llama_index.core.tools.types.DefaultToolFnSchema'>)\n",
            "ToolMetadata(description='Useful for retrieving specific context or particular content in detail from the paper of Paper-METAGPT_META_PROGRAMMING_FOR_A_MULTI-AGENT_COLLABORATIVE_FRAMEWORK', name='vector_tool_METAGPT_META_PROGRAMMING_MULTI', fn_schema=<class 'pydantic.v1.main.vector_tool_METAGPT_META_PROGRAMMING_MULTI'>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.agent import FunctionCallingAgentWorker\n",
        "from llama_index.core.agent import AgentRunner\n",
        "\n",
        "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
        "    tool_retriever=obj_retriever,\n",
        "    llm=llm,\n",
        "    system_prompt=\"You are an agent designed to answer queries over a set of given papers. \\\n",
        "    Please always use the tools provided to answer a question. Do not rely on prior knowledge.\",\n",
        "    verbose=True,\n",
        ")\n",
        "agent = AgentRunner(agent_worker)"
      ],
      "metadata": {
        "id": "qrp7xcPp-5P9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.query(\n",
        "    \"Tell me about the evaluation dataset used in MetaGPT and compare it against SWE-Bench, just the brief info is enough\"\n",
        ")\n",
        "print(str(response), \"\\n\")\n",
        "response = agent.query(\n",
        "    \"Compare and contrast the LoRA papers (LongLoRA, LoftQ), remember to analyze the detail approach in each paper first\"\n",
        ")\n",
        "print(str(response))"
      ],
      "metadata": {
        "id": "B8z7TQ78-5PN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d48fb2c-76d3-410a-fc71-9974a795a9f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added user message to memory: Tell me about the evaluation dataset used in MetaGPT and compare it against SWE-Bench, just the brief info is enough\n",
            "=== Calling Function ===\n",
            "Calling function: summary_tool_METAGPT_META_PROGRAMMING_MULTI with args: {\"input\": \"evaluation dataset\"}\n",
            "=== Calling Function ===\n",
            "Calling function: summary_tool_SWE_BENCH_CAN_LANGUAGE_MODELS with args: {\"input\": \"evaluation dataset\"}\n",
            "assistant: The evaluation dataset used in MetaGPT includes three benchmarks: HumanEval, MBPP, and SoftwareDev. HumanEval consists of 164 handwritten programming tasks, MBPP comprises 427 Python tasks, and SoftwareDev contains 70 representative examples of software development tasks with diverse scopes. These datasets are used to evaluate the functional accuracy, executability, cost, code statistics, productivity, and human revision cost of the generated code.\n",
            "\n",
            "On the other hand, the evaluation dataset in SWE-Bench is designed to assess the performance of language models in resolving real-world software engineering challenges. It consists of task instructions, issue text, retrieved files and documentation, example patch files, and prompts for generating patch files. The dataset includes 2294 task instances constructed from pull requests meeting specific criteria, continuously updated and validated through an execution-based process. It also provides a development set for model evaluation and hyperparameter tuning, with statistics on test instances from open source repositories. \n",
            "\n",
            "Added user message to memory: Compare and contrast the LoRA papers (LongLoRA, LoftQ), remember to analyze the detail approach in each paper first\n",
            "=== Calling Function ===\n",
            "Calling function: vector_tool_LONGLO_EFFICIENT_FINE_TUNING with args: {\"query\": \"detailed approach\"}\n",
            "=== Calling Function ===\n",
            "Calling function: vector_tool_LOFTQ_LORA_FINE_TUNING_AWARE_Q with args: {\"query\": \"detailed approach\"}\n",
            "assistant: The LongLoRA paper focuses on proposing a method to efficiently extend the context length of Large Language Models (LLMs) significantly. It introduces S2-Attn at the architecture level to approximate the standard self-attention pattern during training, reducing GPU memory cost and training time compared to standard full fine-tuning. The method bridges the gap between LoRA and full fine-tuning using trainable normalization and embedding, enabling the extension of Llama2 7B to 100k context length and 70B model to 32k context length on a single machine. It also involves creating a long instruction-following dataset, LongAlpaca, and supervised fine-tuning with LongLoRA.\n",
            "\n",
            "On the other hand, the LoftQ paper's approach involves applying quantization and low-rank approximation alternately to approximate the original high-precision pre-trained weights. The process starts with initializing the network by minimizing the objective that considers LoRA fine-tuning. The minimization problem is solved through alternating between quantization and singular value decomposition (SVD). At each step, the difference between the original pre-trained weight matrix and the low-rank approximation from the previous step is quantized to obtain the quantized weight matrix. Subsequently, SVD is applied to the residual of the quantization to obtain a rank-r approximation. This alternating optimization process helps find a closer initialization to the pre-trained weight, improving performance in downstream tasks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CoT and Agent Reasoning Loop"
      ],
      "metadata": {
        "id": "L7u8yTnQHlPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import (\n",
        "    SimpleDirectoryReader,\n",
        "    VectorStoreIndex,\n",
        "    StorageContext,\n",
        "    load_index_from_storage,\n",
        ")\n",
        "\n",
        "# ref: https://docs.llamaindex.ai/en/stable/examples/agent/react_agent_with_query_engine/\n",
        "march_2022 = SimpleDirectoryReader(\n",
        "    input_files=[\"./uber_financial_march_2022.pdf\"]\n",
        ").load_data()\n",
        "june_2022 = SimpleDirectoryReader(\n",
        "    input_files=[\"./uber_financial_june_2022.pdf\"]\n",
        ").load_data()\n",
        "september_2022 = SimpleDirectoryReader(\n",
        "    input_files=[\"./uber_financial_september_2022.pdf\"]\n",
        ").load_data()"
      ],
      "metadata": {
        "id": "FmLukrTz-5CM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo\")"
      ],
      "metadata": {
        "id": "o5kl64F1-4_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
        "\n",
        "def get_tool(\n",
        "    name,\n",
        "    full_name,\n",
        "    documents = None,\n",
        "):\n",
        "    if not os.path.exists(f\"./{name}\"):\n",
        "        vector_index = VectorStoreIndex.from_documents(documents)\n",
        "        vector_index.storage_context.persist(persist_dir=f\"./{name}\")\n",
        "    else:\n",
        "        vector_index = load_index_from_storage(\n",
        "            StorageContext.from_defaults(persist_dir=f\"./{name}\"),\n",
        "        )\n",
        "\n",
        "    query_engine = vector_index.as_query_engine(\n",
        "        similarity_top_k=3,\n",
        "        llm=llm,\n",
        "    )\n",
        "    query_engine_tool = QueryEngineTool(\n",
        "        query_engine=query_engine,\n",
        "        metadata=ToolMetadata(\n",
        "            name=name,\n",
        "            description=(\n",
        "                \"Provides information about Uber quarterly financials ending\"\n",
        "                f\" {full_name}\"\n",
        "            ),\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    return query_engine_tool"
      ],
      "metadata": {
        "id": "66LKNPKhEMN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "march_tool = get_tool(\"march_2022\", \"March 2022\", documents=march_2022)\n",
        "june_tool = get_tool(\"june_2022\", \"June 2022\", documents=june_2022)\n",
        "september_tool = get_tool(\"september_2022\", \"September 2022\", documents=september_2022)\n",
        "\n",
        "query_engine_tools = [march_tool, june_tool, september_tool]"
      ],
      "metadata": {
        "id": "bFD5YvcEEMKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.agent import AgentRunner, ReActAgent\n",
        "from llama_index.agent.openai import OpenAIAgentWorker, OpenAIAgent\n",
        "from llama_index.agent.openai import OpenAIAgentWorker\n",
        "\n",
        "#agent_llm = OpenAI(model=\"gpt-4o\")\n",
        "agent_llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
        "\n",
        "agent = ReActAgent.from_tools(\n",
        "    query_engine_tools,\n",
        "    llm=agent_llm,\n",
        "    verbose=True,\n",
        "    max_iterations=15,\n",
        ")"
      ],
      "metadata": {
        "id": "wo1q6uE2EMEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "response = agent.chat(\n",
        "    \"Analyze the changes in Uber R&D expenditures and revenue in year 2022 and provide a comprehensive report.\"\n",
        ")\n",
        "'''\n",
        "# leverage the power of CoT and ReAct to make GPT 3.5 think like 4\n",
        "response = agent.chat(\n",
        "    \"Analyze the changes in Uber R&D expenditures and revenue in year 2022 and provide a comprehensive report, you need to \\\n",
        "    gather information from the quarterly financials ending Mar. 2022, Jun. 2022 and Sept. 2022 to perform the analysis, \\\n",
        "    don't assume the analysis is completed before gathering similar information for the subsequent quarters if available.\"\n",
        ")"
      ],
      "metadata": {
        "id": "xB2OnAzUFLjv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c56f430-5591-4302-c2f4-ebf0348f7c3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;3;38;5;200mThought: The user is requesting an analysis of Uber's R&D expenditures and revenue in 2022 using quarterly financial data. I need to gather information from the quarterly financials ending March 2022, June 2022, and September 2022 to perform the analysis.\n",
            "Action: march_2022\n",
            "Action Input: {'input': 'R&D expenditures and revenue'}\n",
            "\u001b[0m\u001b[1;3;34mObservation: Research and development expenses increased by $72 million, or 14%, primarily due to a $63 million increase in stock-based compensation expense. Revenue increased by $4.0 billion, or 136%, primarily driven by increases in Mobility Trip volumes as the business recovers from the impacts of COVID-19, and a $1.5 billion increase in Freight revenue resulting primarily from the acquisition of Transplace in the fourth quarter of 2021.\n",
            "\u001b[0m\u001b[1;3;38;5;200mThought: I have gathered information on Uber's R&D expenditures and revenue for the quarter ending March 2022. I need to gather similar information for the quarters ending June 2022 and September 2022 to complete the analysis.\n",
            "Action: june_2022\n",
            "Action Input: {'input': 'R&D expenditures and revenue'}\n",
            "\u001b[0m\u001b[1;3;34mObservation: Research and development expenses increased by $216 million, or 44%, for the three months ended June 30, 2022, compared to the same period in 2021. Additionally, for the six months ended June 30, 2022, research and development expenses increased by $288 million, or 29%, compared to the same period in 2021.\n",
            "\u001b[0m\u001b[1;3;38;5;200mThought: I have gathered information on Uber's R&D expenditures for the quarters ending March 2022 and June 2022. I need to gather similar information for the quarter ending September 2022 to complete the analysis.\n",
            "Action: september_2022\n",
            "Action Input: {'input': 'R&D expenditures and revenue'}\n",
            "\u001b[0m\u001b[1;3;34mObservation: Research and development expenses increased significantly, primarily due to higher stock-based compensation and employee headcount costs. Revenue is generated mainly from fees paid by Drivers and Merchants for platform use, with revenue recognized upon completion of a trip.\n",
            "\u001b[0m\u001b[1;3;38;5;200mThought: I have gathered information on Uber's R&D expenditures and revenue for all three quarters in 2022. Now, I can analyze the changes in R&D expenditures and revenue for the year 2022.\n",
            "Answer: In 2022, Uber experienced significant increases in research and development expenses, driven by higher stock-based compensation and employee headcount costs. On the revenue side, the company saw substantial growth, primarily from fees paid by Drivers and Merchants for platform use, with revenue recognized upon completion of a trip. The increase in revenue was also influenced by the recovery of Mobility Trip volumes and the acquisition of Transplace, leading to a significant overall revenue growth of 136% in the first quarter.\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initiate a step-wise execution\n",
        "task = agent.create_task(\n",
        "    \"Analyze the changes in Uber R&D expenditures and revenue in year 2022 and provide a comprehensive report, you need to \\\n",
        "    gather information from the quarterly financials ending Mar. 2022, Jun. 2022 and Sept. 2022 to perform the analysis, \\\n",
        "    don't assume the analysis is completed before gathering similar information for the subsequent quarters if available.\"\n",
        ")\n",
        "\n",
        "step_output = agent.run_step(task.task_id)\n",
        "print(step_output.is_last)"
      ],
      "metadata": {
        "id": "oKWLSsrEFLKh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05771b6c-80fa-4301-f171-a3fcde179e03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;3;38;5;200mThought: The user is requesting an analysis of Uber's R&D expenditures and revenue changes in 2022 based on quarterly financial data ending in March 2022, June 2022, and September 2022. I need to gather information from the quarterly financial reports for each of these periods to provide a comprehensive analysis.\n",
            "Action: march_2022\n",
            "Action Input: {'input': 'R&D expenditures and revenue analysis'}\n",
            "\u001b[0m\u001b[1;3;34mObservation: Research and development expenses increased by $72 million, or 14%, primarily due to a $63 million increase in stock-based compensation expense. Revenue increased by $4.0 billion, or 136%, driven by increases in Mobility Trip volumes and Freight revenue.\n",
            "\u001b[0mFalse\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's put human in the loop now\n",
        "step_output = agent.run_step(\n",
        "    task.task_id,\n",
        "    input=\"Great! Continue with your planned steps, and at last compare the financials data with DiDi for the same period.\")"
      ],
      "metadata": {
        "id": "6v8EH1CXjI9l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfbd045a-ab71-4c51-d3be-ec36898df844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added user message to memory: Great! Continue with your planned steps, and at last compare the financials data with DiDi for the same period.\n",
            "\u001b[1;3;38;5;200mThought: I need to gather information from the quarterly financial reports for June 2022 and September 2022 to compare Uber's financial data with DiDi for the same period.\n",
            "Action: june_2022\n",
            "Action Input: {'input': 'R&D expenditures and revenue analysis'}\n",
            "\u001b[0m\u001b[1;3;34mObservation: Research and development expenses increased by $216 million, or 44%, for the three months ended June 30, 2022, compared to the same period in 2021. This increase was primarily driven by a $128 million rise in stock-based compensation and a $90 million increase in employee headcount costs. For the six months ended June 30, 2022, research and development expenses rose by $288 million, or 29%, compared to the same period in 2021. This increase was mainly due to a $191 million increase in stock-based compensation and a $145 million increase in employee headcount costs.\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while not step_output.is_last:\n",
        "     step_output = agent.run_step(task.task_id)\n",
        "step_output = agent.finalize_response(task.task_id)"
      ],
      "metadata": {
        "id": "hax0PDVNjIyV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c098326-688b-4384-bf38-72e739feb772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;3;38;5;200mThought: I have gathered information from the quarterly financial reports ending in March 2022 and June 2022. Now, I need to gather information from the quarterly financial report ending in September 2022 to complete the analysis and compare Uber's financial data with DiDi for the same period.\n",
            "Action: september_2022\n",
            "Action Input: {'input': 'R&D expenditures and revenue analysis'}\n",
            "\u001b[0m\u001b[1;3;34mObservation: Research and development expenses increased significantly over the specified periods, primarily due to higher stock-based compensation and increased employee headcount costs. These expenses are expected to continue to vary as a percentage of revenue as the company invests in ongoing improvements and maintenance of its platform offerings. On the revenue side, the company generates its revenue from fees paid by Drivers and Merchants for platform use. The revenue recognition model varies based on the service provided, with revenue recognized when a trip is complete in certain markets. The company expects its cost of revenue to fluctuate in line with changes in Trip volume on the platform.\n",
            "\u001b[0m\u001b[1;3;38;5;200mThought: I have gathered information from the quarterly financial reports ending in March 2022, June 2022, and September 2022. Based on the data collected, Uber's research and development expenses have increased significantly due to higher stock-based compensation and increased employee headcount costs. The revenue growth is driven by fees paid by Drivers and Merchants for platform use, with revenue recognized upon completion of a trip. The company expects its cost of revenue to fluctuate in line with changes in Trip volume on the platform. Now, I will compare Uber's financial data with DiDi for the same period.\n",
            "Answer: I can answer without using any more tools. I'll use the user's language to compare Uber's financial data with DiDi for the same period.\n",
            "\n",
            "To compare Uber's financial data with DiDi for the same period, we need to gather similar financial information from DiDi for the quarters ending in March 2022, June 2022, and September 2022. By analyzing the R&D expenditures and revenue trends of both companies over these periods, we can provide a comprehensive comparison of their financial performance.\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BXCW6jlGqSla"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}